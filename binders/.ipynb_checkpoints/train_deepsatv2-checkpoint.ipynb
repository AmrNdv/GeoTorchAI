{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d32388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from geotorch.models.raster import DeepSatV2\n",
    "from geotorch.datasets.raster import EuroSAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de942e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define parameters\n",
    "epoch_nums = 100\n",
    "learning_rate = 0.0002\n",
    "batch_size = 16\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed = int(time.time())\n",
    "params = {'batch_size': batch_size, 'shuffle': False}\n",
    "\n",
    "## make sure that PATH_TO_DATASET exists in the running directory\n",
    "PATH_TO_DATASET = \"data/eurosat\"\n",
    "MODEL_SAVE_PATH = \"model-deepsatv2\"\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data and calculate mean and std to perform normalization transform\n",
    "## Set download=True if dataset is not available in the given path\n",
    "fullData = EuroSAT(root = PATH_TO_DATASET, download=False)\n",
    "\n",
    "full_loader = DataLoader(fullData, batch_size= batch_size)\n",
    "channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "for i, sample in enumerate(full_loader):\n",
    "    data_temp, _ = sample\n",
    "    channels_sum += torch.mean(data_temp, dim=[0, 2, 3])\n",
    "    channels_squared_sum += torch.mean(data_temp**2, dim=[0, 2, 3])\n",
    "    num_batches += 1\n",
    "\n",
    "mean = channels_sum / num_batches\n",
    "std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8031f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the transform operation\n",
    "sat_transform = transforms.Normalize(mean, std)\n",
    "## Load data with desired transformation and additional handcrafted features enabled\n",
    "fullData = EuroSAT(root = PATH_TO_DATASET, include_additional_features = True, transform = sat_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aea44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize training and validation indices to split the dataset\n",
    "dataset_size = len(fullData)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define training and validation data sampler\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "## Define training and validation data loader\n",
    "train_loader = DataLoader(fullData, **params, sampler=train_sampler)\n",
    "val_loader = DataLoader(fullData, **params, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set device to CPU or GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "## Define Model\n",
    "model = DeepSatV2(13, 64, 64, 10, len(fullData.ADDITIONAL_FEATURES))\n",
    "## Define hyper-parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.to(device)\n",
    "loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a51413",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before starting training, define a method to calculate validation accuracy\n",
    "def get_validation_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_sample = 0\n",
    "    correct = 0\n",
    "    for i, sample in enumerate(data_loader):\n",
    "        inputs, labels, features = sample\n",
    "        inputs = inputs.to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs, features)\n",
    "        total_sample += len(labels)\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total_sample\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a17b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform training and validation\n",
    "max_val_accuracy = None\n",
    "for e in range(epoch_nums):\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        inputs, labels, features = sample\n",
    "        inputs = inputs.to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs, features)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Training Loss: {:.4f}'.format(e + 1, epoch_nums, loss.item()))\n",
    "\n",
    "    ## Perform model validation after finishing each epoch training\n",
    "    val_accuracy = get_validation_accuracy(model, val_loader, device)\n",
    "    print(\"Validation Accuracy: \", val_accuracy, \"%\")\n",
    "\n",
    "    if max_val_accuracy == None or val_accuracy > max_val_accuracy:\n",
    "        max_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print('Best model saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
